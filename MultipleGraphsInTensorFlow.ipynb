{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g1 = tf.Graph() \n",
    "with g1.as_default() as g:\n",
    "    with g.name_scope( \"g1\" ) as scope:\n",
    "        matrix11 = tf.constant([[3., 3.]])\n",
    "        matrix21 = tf.constant([[2.],[2.]])\n",
    "        product1 = tf.matmul(matrix11, matrix21)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "g2 = tf.Graph() \n",
    "with g2.as_default() as g:\n",
    "    with g.name_scope( \"g2\" ) as scope:\n",
    "        matrix12 = tf.constant([[4., 4.]])\n",
    "        matrix22 = tf.constant([[5.],[5.]])\n",
    "        product2 = tf.matmul(matrix12, matrix22)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session( graph = g1 ) as sess:\n",
    "    result = sess.run( product1 )\n",
    "    print( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float divmod()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-76f46cc81a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0mk_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0msumm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float divmod()"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#g1=tf.Graph()\n",
    "#tf.reset_default_graph()\n",
    "k = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Make a normal distribution, with a shifting mean\n",
    "mean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)\n",
    "# Record that distribution into a histogram summary\n",
    "tf.summary.histogram(\"normal/moving_mean\", mean_moving_normal)\n",
    "\n",
    "# Make a normal distribution with shrinking variance\n",
    "variance_shrinking_normal = tf.random_normal(shape=[1000], mean=0, stddev=1-(k))\n",
    "# Record that distribution too\n",
    "tf.summary.histogram(\"normal/shrinking_variance\", variance_shrinking_normal)\n",
    "\n",
    "# Let's combine both of those distributions into one dataset\n",
    "normal_combined = tf.concat([mean_moving_normal, variance_shrinking_normal], 0)\n",
    "# We add another histogram summary to record the combined distribution\n",
    "tf.summary.histogram(\"normal/bimodal\", normal_combined)\n",
    "\n",
    "# Add a gamma distribution\n",
    "gamma = tf.random_gamma(shape=[1000], alpha=k)\n",
    "tf.summary.histogram(\"gamma\", gamma)\n",
    "\n",
    "# And a poisson distribution\n",
    "poisson = tf.random_poisson(shape=[1000], lam=k)\n",
    "tf.summary.histogram(\"poisson\", poisson)\n",
    "\n",
    "# And a uniform distribution\n",
    "uniform = tf.random_uniform(shape=[1000], maxval=k*10)\n",
    "tf.summary.histogram(\"uniform\", uniform)\n",
    "\n",
    "# Finally, combine everything together!\n",
    "all_distributions = [mean_moving_normal, variance_shrinking_normal,\n",
    "                     gamma, poisson, uniform]\n",
    "all_combined = tf.concat(all_distributions, 0)\n",
    "tf.summary.histogram(\"all_combined\", all_combined)\n",
    "\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "# Setup a session and summary writer\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter(\"/tmp/histogram_example\")\n",
    "\n",
    "# Setup a loop and write the summaries to disk\n",
    "N = 400\n",
    "for step in range(N):\n",
    "  k_val = float(N) // step\n",
    "  summ = sess.run(summaries, feed_dict={k: k_val})\n",
    "  writer.add_summary(summ, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
