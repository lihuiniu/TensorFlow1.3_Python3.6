{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is downloaded to /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmpqj286sj5\n",
      "Test data is downloaded to /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmp9bzvsjdh\n",
      "Prediction data is downloaded to /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmpvuepcr5r\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmploo8zss8\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmploo8zss8', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmploo8zss8/model.ckpt.\n",
      "INFO:tensorflow:loss = 100.652, step = 1\n",
      "INFO:tensorflow:global_step/sec: 809.266\n",
      "INFO:tensorflow:loss = 8.89334, step = 101 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1125.06\n",
      "INFO:tensorflow:loss = 6.70184, step = 201 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.131\n",
      "INFO:tensorflow:loss = 9.95237, step = 301 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 975.295\n",
      "INFO:tensorflow:loss = 10.0265, step = 401 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 894.67\n",
      "INFO:tensorflow:loss = 7.37456, step = 501 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1016.47\n",
      "INFO:tensorflow:loss = 9.26377, step = 601 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 886.425\n",
      "INFO:tensorflow:loss = 6.09674, step = 701 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 902.95\n",
      "INFO:tensorflow:loss = 6.88495, step = 801 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 942.968\n",
      "INFO:tensorflow:loss = 6.0587, step = 901 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 903.637\n",
      "INFO:tensorflow:loss = 5.51532, step = 1001 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.258\n",
      "INFO:tensorflow:loss = 6.25629, step = 1101 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.712\n",
      "INFO:tensorflow:loss = 8.74981, step = 1201 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.01\n",
      "INFO:tensorflow:loss = 7.53128, step = 1301 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.047\n",
      "INFO:tensorflow:loss = 6.89776, step = 1401 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 903.088\n",
      "INFO:tensorflow:loss = 5.68338, step = 1501 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 848.175\n",
      "INFO:tensorflow:loss = 5.40915, step = 1601 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1070.42\n",
      "INFO:tensorflow:loss = 6.28246, step = 1701 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.383\n",
      "INFO:tensorflow:loss = 7.26189, step = 1801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 842.744\n",
      "INFO:tensorflow:loss = 9.20164, step = 1901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 875.442\n",
      "INFO:tensorflow:loss = 7.46145, step = 2001 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 907.277\n",
      "INFO:tensorflow:loss = 4.89651, step = 2101 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 920.344\n",
      "INFO:tensorflow:loss = 7.45079, step = 2201 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.9\n",
      "INFO:tensorflow:loss = 6.24899, step = 2301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.149\n",
      "INFO:tensorflow:loss = 5.8108, step = 2401 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.616\n",
      "INFO:tensorflow:loss = 7.22021, step = 2501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 873.897\n",
      "INFO:tensorflow:loss = 7.10623, step = 2601 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.347\n",
      "INFO:tensorflow:loss = 5.62416, step = 2701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.752\n",
      "INFO:tensorflow:loss = 5.30238, step = 2801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 880.551\n",
      "INFO:tensorflow:loss = 5.31573, step = 2901 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.345\n",
      "INFO:tensorflow:loss = 6.08175, step = 3001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.931\n",
      "INFO:tensorflow:loss = 5.02447, step = 3101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 907.738\n",
      "INFO:tensorflow:loss = 6.50407, step = 3201 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.21\n",
      "INFO:tensorflow:loss = 6.23575, step = 3301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1028.82\n",
      "INFO:tensorflow:loss = 5.07143, step = 3401 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 893.774\n",
      "INFO:tensorflow:loss = 4.30438, step = 3501 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.162\n",
      "INFO:tensorflow:loss = 6.04561, step = 3601 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.147\n",
      "INFO:tensorflow:loss = 3.672, step = 3701 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 1072.12\n",
      "INFO:tensorflow:loss = 6.22442, step = 3801 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1113.01\n",
      "INFO:tensorflow:loss = 5.52163, step = 3901 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 949.956\n",
      "INFO:tensorflow:loss = 5.8659, step = 4001 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 875.451\n",
      "INFO:tensorflow:loss = 6.92198, step = 4101 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.29\n",
      "INFO:tensorflow:loss = 5.35408, step = 4201 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 881.01\n",
      "INFO:tensorflow:loss = 3.1386, step = 4301 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 845.152\n",
      "INFO:tensorflow:loss = 5.13851, step = 4401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1088.91\n",
      "INFO:tensorflow:loss = 6.53909, step = 4501 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.304\n",
      "INFO:tensorflow:loss = 5.15773, step = 4601 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 942.42\n",
      "INFO:tensorflow:loss = 4.92675, step = 4701 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 885.244\n",
      "INFO:tensorflow:loss = 5.64895, step = 4801 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.356\n",
      "INFO:tensorflow:loss = 5.33337, step = 4901 (0.103 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmploo8zss8/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.95939.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-10-07:34:51\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmploo8zss8/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-10-07:34:52\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.52588, rmse = 2.36271\n",
      "Loss: 5.52588\n",
      "Root Mean Squared Error: 2.36271\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/gb/wdr1fnxs23d32krfm7rpnhq80000gn/T/tmploo8zss8/model.ckpt-5000\n",
      "Prediction 1: 4.76513797868\n",
      "Prediction 2: 10.380923006\n",
      "Prediction 3: 7.09635842781\n",
      "Prediction 4: 10.6882737817\n",
      "Prediction 5: 11.0487243904\n",
      "Prediction 6: 9.493814107\n",
      "Prediction 7: 11.2943836526\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/whaleli/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\"\"\"https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/examples/tutorials/estimators/abalone.py\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Learning rate for the model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def maybe_download(train_data, test_data, predict_data):\n",
    "  \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "  if train_data:\n",
    "    train_file_name = train_data\n",
    "  else:\n",
    "    train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_train.csv\",\n",
    "        train_file.name)\n",
    "    train_file_name = train_file.name\n",
    "    train_file.close()\n",
    "    print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "  if test_data:\n",
    "    test_file_name = test_data\n",
    "  else:\n",
    "    test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_test.csv\", test_file.name)\n",
    "    test_file_name = test_file.name\n",
    "    test_file.close()\n",
    "    print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "  if predict_data:\n",
    "    predict_file_name = predict_data\n",
    "  else:\n",
    "    predict_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_predict.csv\",\n",
    "        predict_file.name)\n",
    "    predict_file_name = predict_file.name\n",
    "    predict_file.close()\n",
    "    print(\"Prediction data is downloaded to %s\" % predict_file_name)\n",
    "\n",
    "  return train_file_name, test_file_name, predict_file_name\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "  \"\"\"Model function for Estimator.\"\"\"\n",
    "\n",
    "  # Connect the first hidden layer to input layer\n",
    "  # (features[\"x\"]) with relu activation\n",
    "  first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\n",
    "\n",
    "  # Connect the second hidden layer to first hidden layer with relu\n",
    "  second_hidden_layer = tf.layers.dense(\n",
    "      first_hidden_layer, 10, activation=tf.nn.relu)\n",
    "\n",
    "  # Connect the output layer to second hidden layer (no activation fn)\n",
    "  output_layer = tf.layers.dense(second_hidden_layer, 1)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "\n",
    "  # Provide an estimator spec for `ModeKeys.PREDICT`.\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions={\"ages\": predictions})\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(\n",
    "      learning_rate=params[\"learning_rate\"])\n",
    "  train_op = optimizer.minimize(\n",
    "      loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(labels, tf.float64), predictions)\n",
    "  }\n",
    "\n",
    "  # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load datasets\n",
    "  abalone_train, abalone_test, abalone_predict = maybe_download(\n",
    "      FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)\n",
    "\n",
    "  # Training examples\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_train, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Test examples\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_test, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set of 7 examples for which to predict abalone ages\n",
    "  prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_predict, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set model params\n",
    "  model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "  # Instantiate Estimator\n",
    "  nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)\n",
    "\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(training_set.data)},\n",
    "      y=np.array(training_set.target),\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "  # Train\n",
    "  nn.train(input_fn=train_input_fn, steps=5000)\n",
    "\n",
    "  # Score accuracy\n",
    "  test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(test_set.data)},\n",
    "      y=np.array(test_set.target),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  ev = nn.evaluate(input_fn=test_input_fn)\n",
    "  print(\"Loss: %s\" % ev[\"loss\"])\n",
    "  print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])\n",
    "\n",
    "  # Print out predictions\n",
    "  predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": prediction_set.data},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "  predictions = nn.predict(input_fn=predict_input_fn)\n",
    "  for i, p in enumerate(predictions):\n",
    "    print(\"Prediction %s: %s\" % (i + 1, p[\"ages\"]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "  parser.add_argument(\n",
    "      \"--train_data\", type=str, default=\"\", help=\"Path to the training data.\")\n",
    "  parser.add_argument(\n",
    "      \"--test_data\", type=str, default=\"\", help=\"Path to the test data.\")\n",
    "  parser.add_argument(\n",
    "      \"--predict_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the prediction data.\")\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
